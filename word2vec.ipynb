{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cell_Phones_and_Accessories = pd.read_json('~/Documents/Msc-project/data/reviews_Cell_Phones_and_Accessories_5.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords=[]\n",
    "with open('stopwords.txt') as file:\n",
    "    for line in file.readlines():\n",
    "        stopwords.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194439/194439 [00:51<00:00, 3745.49it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "with tqdm(total = len(Cell_Phones_and_Accessories)) as pbar:\n",
    "    for review in Cell_Phones_and_Accessories.iloc[:,3]:\n",
    "        review = nltk.sent_tokenize(review)\n",
    "        for i in range(len(review)):\n",
    "            review[i] = review[i].lower()\n",
    "            for punc in string.punctuation:\n",
    "                review[i] = review[i].replace(punc, ' ')\n",
    "        sentences.append(review)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001122\n"
     ]
    }
   ],
   "source": [
    "s = []\n",
    "for sentence in sentences:\n",
    "    for ss in sentence:\n",
    "        s.append(ss)\n",
    "print len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001122/1001122 [02:10<00:00, 7661.47it/s]\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total = len(s)) as pbar:\n",
    "    for i in range(len(s)):\n",
    "        s[i] = nltk.word_tokenize(s[i])\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001122/1001122 [07:17<00:00, 2289.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'look', u'good', u'stick', u'good'], [u'just', u'don', u'like', u'rounded', u'shape', u'always', u'bumping', u'siri', u'kept', u'popping', u'irritating']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total = len(s)) as pbar:\n",
    "    for i in range(len(s)):\n",
    "        new_sent = []\n",
    "        for word in s[i]:\n",
    "            if word not in stopwords and len(word)>2:\n",
    "                new_sent.append(word)\n",
    "        s[i] = new_sent\n",
    "        pbar.update(1)\n",
    "print s[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.79212523549\n"
     ]
    }
   ],
   "source": [
    "lens = [len(sen) for sen in s]\n",
    "print np.mean(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(s, size=100, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('word2vec-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_dict = {}\n",
    "for key in keys:\n",
    "    key_dict[key] = 0\n",
    "for sentence in s:\n",
    "    for word in sentence:\n",
    "        if key_dict.has_key(word):\n",
    "            key_dict[word] += 1\n",
    "key_list = sorted(key_dict.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 3228/194439 time to go 79336\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process PoolWorker-44:\n",
      "Process PoolWorker-43:\n",
      "Process PoolWorker-41:\n",
      "Process PoolWorker-42:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "  File \"/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 3229/194439 time to go 79328\r",
      "done 3230/194439 time to go 79343\r",
      "done 3231/194439 time to go 79359\r",
      "done 3232/194439 time to go 79374\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "    result = (True, func(*args, **kwds))\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-23-0f22437a89ac>\", line 17, in pros\n",
      "  File \"<ipython-input-23-0f22437a89ac>\", line 17, in pros\n",
      "  File \"<ipython-input-23-0f22437a89ac>\", line 17, in pros\n",
      "    similar_words = model.most_similar(word)\n",
      "  File \"<ipython-input-23-0f22437a89ac>\", line 17, in pros\n",
      "    similar_words = model.most_similar(word)\n",
      "  File \"/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/site-packages/gensim/models/word2vec.py\", line 1209, in most_similar\n",
      "  File \"/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/site-packages/gensim/models/word2vec.py\", line 1209, in most_similar\n",
      "    return self.wv.most_similar(positive, negative, topn, restrict_vocab, indexer)\n",
      "    similar_words = model.most_similar(word)\n",
      "    similar_words = model.most_similar(word)\n",
      "  File \"/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/site-packages/gensim/models/keyedvectors.py\", line 346, in most_similar\n",
      "  File \"/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/site-packages/gensim/models/word2vec.py\", line 1209, in most_similar\n",
      "    return self.wv.most_similar(positive, negative, topn, restrict_vocab, indexer)\n",
      "    dists = dot(limited, mean)\n",
      "    return self.wv.most_similar(positive, negative, topn, restrict_vocab, indexer)\n",
      "  File \"/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/site-packages/gensim/models/word2vec.py\", line 1209, in most_similar\n",
      "  File \"/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/site-packages/gensim/models/keyedvectors.py\", line 346, in most_similar\n",
      "KeyboardInterrupt\n",
      "    return self.wv.most_similar(positive, negative, topn, restrict_vocab, indexer)\n",
      "  File \"/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/site-packages/gensim/models/keyedvectors.py\", line 346, in most_similar\n",
      "  File \"/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/site-packages/gensim/models/keyedvectors.py\", line 346, in most_similar\n",
      "    dists = dot(limited, mean)\n",
      "    dists = dot(limited, mean)\n",
      "KeyboardInterrupt\n",
      "    dists = dot(limited, mean)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-0f22437a89ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0minit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCell_Phones_and_Accessories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     sys.stdout.write('done %d/%d time to go %d\\r' % (cnt,len(Cell_Phones_and_Accessories), \n\u001b[1;32m     35\u001b[0m                                                      (len(Cell_Phones_and_Accessories)-cnt)/(time.time()-init_time)*cnt/60))\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import sys\n",
    "import time\n",
    "def pros(review):\n",
    "    review = review.lower()\n",
    "    for punc in string.punctuation:\n",
    "        review = review.replace(punc, ' ')\n",
    "    review = nltk.word_tokenize(review)\n",
    "    feature_vector = np.zeros(1000)\n",
    "    feature_dict = {}\n",
    "    for feature in features:\n",
    "        feature_dict[feature] = 0\n",
    "    for word in review:\n",
    "        similar_words = []\n",
    "        if word not in stopwords and len(word)>2:\n",
    "            if model.wv.vocab.has_key(word):\n",
    "                similar_words = model.most_similar(word)\n",
    "        for similar_word_pair in similar_words:\n",
    "            similar_word = u''+similar_word_pair[0]\n",
    "            if feature_dict.has_key(similar_word):\n",
    "                feature_dict[similar_word] += 1\n",
    "    for i in range(len(features)):\n",
    "        feature_vector[i] = feature_dict[features[i]]\n",
    "    feature_matrix.append(feature_vector)\n",
    "    \n",
    "    \n",
    "features = np.array(key_list[:1000])[:,0]\n",
    "feature_matrix = []\n",
    "cnt = 1\n",
    "cores = multiprocessing.cpu_count()\n",
    "pool = multiprocessing.Pool(processes=cores)\n",
    "init_time = time.time()\n",
    "for _ in pool.imap_unordered(pros, Cell_Phones_and_Accessories.iloc[:,3]):\n",
    "    sys.stdout.write('done %d/%d time to go %d\\r' % (cnt,len(Cell_Phones_and_Accessories), \n",
    "                                                     (len(Cell_Phones_and_Accessories)-cnt)/(time.time()-init_time)*cnt/60))\n",
    "    cnt += 1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "print cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2314/194439 [01:31<2:06:57, 25.22it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-caff470d474a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                     \u001b[0msimilar_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msimilar_word_pair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimilar_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0msimilar_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msimilar_word_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0mRefer\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocumentation\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m         \"\"\"\n\u001b[0;32m-> 1209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwmdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s16/s1678999/miniconda2/envs/msc/lib/python2.7/site-packages/gensim/models/keyedvectors.pyc\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mlimited\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0norm\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrestrict_vocab\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimited\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "features = np.array(key_list[:1000])[:,0]\n",
    "feature_matrix = []\n",
    "with tqdm(total = len(Cell_Phones_and_Accessories)) as pbar:\n",
    "    for review in Cell_Phones_and_Accessories.iloc[:,3]:\n",
    "        review = review.lower()\n",
    "        for punc in string.punctuation:\n",
    "            review = review.replace(punc, ' ')\n",
    "        review = nltk.word_tokenize(review)\n",
    "        feature_vector = np.zeros(1000)\n",
    "        feature_dict = {}\n",
    "        for feature in features:\n",
    "            feature_dict[feature] = 0\n",
    "        for word in review:\n",
    "            similar_words = []\n",
    "            if word not in stopwords and len(word)>2:\n",
    "                if model.wv.vocab.has_key(word):\n",
    "                    similar_words = model.most_similar(word)\n",
    "            for similar_word_pair in similar_words:\n",
    "                similar_word = u''+similar_word_pair[0]\n",
    "                if feature_dict.has_key(similar_word):\n",
    "                    feature_dict[similar_word] += 1\n",
    "        for i in range(len(features)):\n",
    "            feature_vector[i] = feature_dict[features[i]]\n",
    "        feature_matrix.append(feature_vector)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29341446.0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('word2vec_feature_matrix',feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('word2vec_feature_matrix.csv', feature_matrix, delimiter = ',')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
